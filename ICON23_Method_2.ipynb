{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SoumyaTeotia/Cross-Domain-Multi-Intent-Identification-in-Low-Resource-Languages/blob/main/ICON23_Method_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install langchain openai tiktoken chromadb datasets"
      ],
      "metadata": {
        "id": "DmUbOetgty-h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f180ce3-a3c4-4125-91c1-2e30219fc54f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.9/815.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.0/509.0 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.6/536.6 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.1/41.1 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.9/57.9 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.6/105.6 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m698.9/698.9 kB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.3/38.3 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "ibis-framework 7.1.0 requires pyarrow<15,>=2, but you have pyarrow 15.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import CSVLoader\n",
        "from langchain.indexes import VectorstoreIndexCreator\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.llms import OpenAI\n",
        "import datasets\n",
        "import os\n",
        "import openai\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.document_loaders import DirectoryLoader\n",
        "\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.document_loaders import DataFrameLoader\n",
        "from getpass import getpass"
      ],
      "metadata": {
        "id": "FD6qii8AuDOY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = getpass()\n",
        "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
      ],
      "metadata": {
        "id": "VxVJWpNesp_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
        "   text = text.replace(\"\\n\", \" \")\n",
        "   response = openai.Embedding.create(\n",
        "   model=\"text-embedding-ada-002\",\n",
        "   input=text\n",
        "   )\n",
        "   return response['data'][0]['embedding']\n",
        "\n",
        "  #  return openai.Embedding.create(input = [text], model=model)['data'][0]['embedding']\n"
      ],
      "metadata": {
        "id": "OafMBql_sMyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate embeddings for the two text items\n",
        "text1 = \"This is the first text item.\"\n",
        "text2 = \"This is the second text item.\"\n",
        "\n",
        "embedding1 = get_embedding(text1)\n",
        "embedding2 = get_embedding(text2)\n",
        "\n",
        "# Compute the cosine similarity between the two embedding vectors\n",
        "cosine_similarity = embedding1.dot(embedding2) / (embedding1.magnitude * embedding2.magnitude)\n",
        "\n",
        "# Print the cosine similarity\n",
        "print(cosine_similarity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "kowxApnYmwxJ",
        "outputId": "8ae0d47c-462b-4812-eb87-3447fd210aea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-b6a66da30f37>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtext2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"This is the second text item.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0membedding1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0membedding2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-e49c7516cab0>\u001b[0m in \u001b[0;36mget_embedding\u001b[0;34m(text, model)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"text-embedding-ada-002\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m    \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m    response = openai.Embedding.create(\n\u001b[0m\u001b[1;32m      6\u001b[0m    \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"text-embedding-ada-002\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m    \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'openai' has no attribute 'Embedding'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai[embeddings]"
      ],
      "metadata": {
        "id": "F2w1enoUlsI0",
        "outputId": "93c2e418-9bab-432a-d0e8-2c04ad71a2ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai[embeddings] in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "\u001b[33mWARNING: openai 1.0.1 does not provide the extra 'embeddings'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai[embeddings]) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai[embeddings]) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai[embeddings]) (0.25.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai[embeddings]) (1.10.13)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai[embeddings]) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai[embeddings]) (4.8.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai[embeddings]) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai[embeddings]) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai[embeddings]) (1.1.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai[embeddings]) (2023.7.22)\n",
            "Requirement already satisfied: httpcore in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai[embeddings]) (1.0.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore->httpx<1,>=0.23.0->openai[embeddings]) (0.14.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai.embeddings_utils import cosine_similarity"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "id": "DaeaewD2ljmv",
        "outputId": "f8375f67-248a-4b35-e3dc-f9fe55f02c8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-cb3589a737a5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mopenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'openai.embeddings_utils'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ":Run this if you do not have a db directory on colab, this loads the embeddings.\n",
        "# Only run this once"
      ],
      "metadata": {
        "id": "3rBDwoZ0xlep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataframe(jsonl_file_path):\n",
        "  # Define the path to your JSONL file\n",
        "  # jsonl_file_path = \"hi-IN.jsonl\"\n",
        "  # Initialize an empty list to store the JSON objects\n",
        "  data = []\n",
        "  # Open and read the JSONL file line by line\n",
        "  with open(jsonl_file_path, \"r\") as jsonl_file:\n",
        "      for line in jsonl_file:\n",
        "          data.append(json.loads(line))\n",
        "  # Create a DataFrame from the list of JSON objects\n",
        "  df = pd.DataFrame(data)\n",
        "  return df\n",
        "df = get_dataframe(\"hi-IN.jsonl\")\n",
        "\n",
        "def pre_process(df):\n",
        "  df['slot_labels'] = df['slot_method']\n",
        "  df['domain'] = df['scenario']\n",
        "  df['annot_utt'] = df['annot_utt']\n",
        "  df_reduced = df[['utt', 'intent', 'slot_labels', 'domain', 'annot_utt']].copy()\n",
        "  for index, row in df_reduced.iterrows():\n",
        "      slot_method_list = row['slot_labels']\n",
        "      slot_values = ', '.join(item['slot'] for item in slot_method_list)\n",
        "      df_reduced.at[index, 'slot_labels'] = slot_values\n",
        "  # Create a new DataFrame with the desired format\n",
        "  new_df = df_reduced[['utt', 'intent', 'slot_labels', 'domain', 'annot_utt']].copy()\n",
        "  return new_df\n",
        "\n",
        "new_df = pre_process(df)\n",
        "\n",
        "def split_df(new_df):\n",
        "  loader = DataFrameLoader(new_df, page_content_column=\"utt\")\n",
        "  documents = loader.load()\n",
        "  text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=200)\n",
        "  texts = text_splitter.split_documents(documents)\n",
        "  return texts\n",
        "texts = split_df(new_df)\n",
        "\n",
        "def store_embeddings(texts):\n",
        "  persist_directory = 'db'\n",
        "  embedding = OpenAIEmbeddings()\n",
        "  vectordb = Chroma.from_documents(documents=texts, embedding=embedding, persist_directory=persist_directory)\n",
        "\n",
        "  # persist the db to disk\n",
        "  vectordb.persist()\n",
        "  vectordb = None\n",
        "\n",
        "  # Now we can load the persisted database from disk, and use it as normal.\n",
        "  vectordb = Chroma(persist_directory=persist_directory,\n",
        "                    embedding_function=embedding)\n",
        "  return vectordb\n",
        "vectordb = store_embeddings(texts)"
      ],
      "metadata": {
        "id": "8PYBkt5zuF5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_relevant_docs(res):\n",
        "  docs = []\n",
        "  for doc in res['source_documents']:\n",
        "    diction = {}\n",
        "    for x in doc:\n",
        "      if x[0] == 'page_content':\n",
        "        diction[\"page_content\"] = x[1]\n",
        "      if x[0] == 'metadata':\n",
        "        diction[\"metadata\"] = x[1]\n",
        "    docs.append(diction)\n",
        "  return docs\n",
        "\n",
        "def get_context(doc):\n",
        "    res = []\n",
        "    for doc in doc:\n",
        "      input_doc = doc['page_content']\n",
        "      intent = doc['metadata']['intent']\n",
        "      domain = doc['metadata']['domain']\n",
        "      #slot_labels = doc['metadata']['slot_labels']\n",
        "\n",
        "      prompt = \"The user utterance - Input : {}.\\n Output : The intent is {}, domain is {} \".format(input_doc, intent, domain)\n",
        "      res.append(prompt)\n",
        "    return res\n",
        "\n",
        "\n",
        "def generate_prompt(user_query, context):\n",
        "  prompt_template = \"\"\"\n",
        "\n",
        "  You are an AI, that is expert in Natural Language Understanding. You should be able to predict the multiple intents and domains in english for the given Bengali input.\n",
        "  \\n {question}\n",
        "  \\n using the below examples in hindi, where the user utterance in given as Input and the domain and intent are given as Output.\n",
        "  {context_prompt_list}\n",
        "  \\n You would be able to capture multiple domains and intents for the user utterence.\n",
        "\n",
        "  Give the output in a json format as follows, append multiple intents, domains and slots to the list below.\n",
        "  Format:\n",
        "\n",
        "  \"intent\": []\n",
        "  \"domain\": []\n",
        "\n",
        "  \"\"\".format(question = user_query, context_prompt_list = '.\\n'.join(context))\n",
        "\n",
        "  return prompt_template\n",
        "\n",
        "def get_intent_label(user_query):\n",
        "  response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": user_query}\n",
        "    ]\n",
        "  )\n",
        "  return json.loads(response[\"choices\"][0][\"message\"][\"content\"])"
      ],
      "metadata": {
        "id": "rvDc1jdPvFro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def final(no_of_docs, user_query):\n",
        "  template = \"\"\" Answer only using the context provided, if you don't know the answer, simply state that you don't know.\n",
        "  The query will be in Hindi, use the stored Bengali data to answer the query\n",
        "\n",
        "  {context}\n",
        "\n",
        "  Question: {question}\n",
        "  \"\"\"\n",
        "  # Creating a prompt\n",
        "  PROMPT = PromptTemplate(template=template, input_variables=[\"context\", \"question\"])\n",
        "  # Create a qa chain\n",
        "  qa_with_source = RetrievalQA.from_chain_type(\n",
        "    llm=ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\"),\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=vectordb.as_retriever(search_kwargs={\"k\": no_of_docs}),\n",
        "    chain_type_kwargs={\"prompt\": PROMPT,},\n",
        "    return_source_documents=True\n",
        "  )\n",
        "  # Get intents for that user_query\n",
        "  res = qa_with_source(user_query)\n",
        "  # Get the similar documents\n",
        "  relevant_docs = get_relevant_docs(res)\n",
        "  # Generate context vector\n",
        "  context = get_context(relevant_docs)\n",
        "  # Combine input and context to get prompt template\n",
        "  prompt_template = generate_prompt(user_query, context)\n",
        "  # Print the prompt template\n",
        "  print(prompt_template)\n",
        "  response = get_intent_label(prompt_template)\n",
        "  # Final response after prompting\n",
        "  return \"The response after prompting is:\\n {}\".format(response)\n"
      ],
      "metadata": {
        "id": "bcAYvjt1uley"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_query_1 = \"সোমবার মহালয়া থাকায়, অনুগ্রহ করে সকাল 4 টার জন্য অ্যালার্ম সেট করুন এবং রেডিও চালু করুন এবং পরিবেশ তৈরি করতে ভলিউমটি সম্পূর্ণ করুন।  এছাড়াও, আপনি কি কিছু ভাল বাঙ্গালী খাবার এর পরামর্শ দিতে পারেন যা আমি রান্না করতে সাহায্য করতে পারি। ভালো কিছু  গান সাজেস্ট করুন।\"\n",
        "user_query_2=\"আপনি কি আমাকে প্যারিস যাওয়ার জন্য একটি ফ্লাইটের পরামর্শ দিতে পারেন যেহেতু আমি খুব ঘন ঘন ভ্রমণকারী এবং বিশ্বের বিভিন্ন স্থান ঘুরে দেখতে পছন্দ করি। এছাড়াও আইফেল টাওয়ারের আশেপাশে কিছু ভাল রেস্তোরাঁ এবং হোটেলের সাথে কিছু পর্যটন স্থানের পরামর্শ দিন যা আমি ঘুরে দেখতে পারি?\"\n",
        "user_query_3=\"অস্টিনে আজ খুব ঠান্ডা। দিবালোক সঞ্চয় ইতিমধ্যে এখানে শুরু হয়েছে। আজকেও তুষারপাত হতে পারে। আমরা অনেক বাংলা গান বাজিয়েছিলাম এবং ডান্ডিয়া রাতে নাচতাম।\"\n",
        "user_query_split = user_query_1.split(\"।\")\n",
        "k = [8 , 12 , 16 , 32]"
      ],
      "metadata": {
        "id": "LkoCxDJJwH5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k_values in k:\n",
        "  output = final(k_values , user_query_2)\n",
        "  print(k_values)\n",
        "  print(user_query_2)\n",
        "  print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DndCUihOCK9g",
        "outputId": "a419fbe4-7f91-4de8-f4e4-de099c43eab8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "  You are an AI, that is expert in Natural Language Understanding. You should be able to predict the multiple intents and domains in english for the given Bengali input.\n",
            "  \n",
            " আপনি কি আমাকে প্যারিস যাওয়ার জন্য একটি ফ্লাইটের পরামর্শ দিতে পারেন যেহেতু আমি খুব ঘন ঘন ভ্রমণকারী এবং বিশ্বের বিভিন্ন স্থান ঘুরে দেখতে পছন্দ করি। এছাড়াও আইফেল টাওয়ারের আশেপাশে কিছু ভাল রেস্তোরাঁ এবং হোটেলের সাথে কিছু পর্যটন স্থানের পরামর্শ দিন যা আমি ঘুরে দেখতে পারি?\n",
            "  \n",
            " using the below examples in hindi, where the user utterance in given as Input and the domain and intent are given as Output.\n",
            "  The user utterance - Input : मेरे आसपास में किन स्थानों से मैं साथ ले जाने के लिए खरीदारी कर सकता हूँ.\n",
            " Output : The intent is takeaway_order, domain is takeaway .\n",
            "The user utterance - Input : मैं स्थानीय पर्यटक के रूप में कहां से खरीदारी कर सकता हूं.\n",
            " Output : The intent is recommendation_locations, domain is recommendation .\n",
            "The user utterance - Input : मैं लखनऊ के आसपास के सिनेमाघरों में कौन सी बाहुबली फिल्म देख सकता हूं.\n",
            " Output : The intent is recommendation_movies, domain is recommendation .\n",
            "The user utterance - Input : मुझे मुंबई और भोपाल के बीच कल के लिए रेलगाड़ी शेड्यूल दिखाओ.\n",
            " Output : The intent is transport_query, domain is transport .\n",
            "The user utterance - Input : मुझे दिखाओ कि मुझे रेलगाड़ी कहाँ से मिल सकती है.\n",
            " Output : The intent is transport_query, domain is transport .\n",
            "The user utterance - Input : मुझे भारत में घूमने के लिए कुछ बेहतरीन पर्यटन स्थल बताएं.\n",
            " Output : The intent is recommendation_locations, domain is recommendation .\n",
            "The user utterance - Input : मैं स्थानीय क्षेत्र में सर्वश्रेष्ठ रेटिंग पब जानना चाहता हूं.\n",
            " Output : The intent is recommendation_locations, domain is recommendation .\n",
            "The user utterance - Input : मुझे मध्य प्रदेश में ग्वालियर के लिए रेलगाड़ी द्वारा दूरी और दिशा का पता लगाएं.\n",
            " Output : The intent is transport_query, domain is transport \n",
            "  \n",
            " You would be able to capture multiple domains and intents for the user utterence.\n",
            "\n",
            "  Give the output in a json format as follows, append multiple intents, domains and slots to the list below. \n",
            "  Format:\n",
            "\n",
            "  \"intent\": []\n",
            "  \"domain\": []\n",
            "\n",
            "  \n",
            "8\n",
            "আপনি কি আমাকে প্যারিস যাওয়ার জন্য একটি ফ্লাইটের পরামর্শ দিতে পারেন যেহেতু আমি খুব ঘন ঘন ভ্রমণকারী এবং বিশ্বের বিভিন্ন স্থান ঘুরে দেখতে পছন্দ করি। এছাড়াও আইফেল টাওয়ারের আশেপাশে কিছু ভাল রেস্তোরাঁ এবং হোটেলের সাথে কিছু পর্যটন স্থানের পরামর্শ দিন যা আমি ঘুরে দেখতে পারি?\n",
            "The response after prompting is:\n",
            " {'intent': ['flight_booking', 'hotel_recommendation', 'restaurant_recommendation'], 'domain': ['travel', 'recommendation']}\n",
            "\n",
            "\n",
            "  You are an AI, that is expert in Natural Language Understanding. You should be able to predict the multiple intents and domains in english for the given Bengali input.\n",
            "  \n",
            " আপনি কি আমাকে প্যারিস যাওয়ার জন্য একটি ফ্লাইটের পরামর্শ দিতে পারেন যেহেতু আমি খুব ঘন ঘন ভ্রমণকারী এবং বিশ্বের বিভিন্ন স্থান ঘুরে দেখতে পছন্দ করি। এছাড়াও আইফেল টাওয়ারের আশেপাশে কিছু ভাল রেস্তোরাঁ এবং হোটেলের সাথে কিছু পর্যটন স্থানের পরামর্শ দিন যা আমি ঘুরে দেখতে পারি?\n",
            "  \n",
            " using the below examples in hindi, where the user utterance in given as Input and the domain and intent are given as Output.\n",
            "  The user utterance - Input : मेरे आसपास में किन स्थानों से मैं साथ ले जाने के लिए खरीदारी कर सकता हूँ.\n",
            " Output : The intent is takeaway_order, domain is takeaway .\n",
            "The user utterance - Input : मैं स्थानीय पर्यटक के रूप में कहां से खरीदारी कर सकता हूं.\n",
            " Output : The intent is recommendation_locations, domain is recommendation .\n",
            "The user utterance - Input : मैं लखनऊ के आसपास के सिनेमाघरों में कौन सी बाहुबली फिल्म देख सकता हूं.\n",
            " Output : The intent is recommendation_movies, domain is recommendation .\n",
            "The user utterance - Input : मुझे मुंबई और भोपाल के बीच कल के लिए रेलगाड़ी शेड्यूल दिखाओ.\n",
            " Output : The intent is transport_query, domain is transport .\n",
            "The user utterance - Input : मुझे दिखाओ कि मुझे रेलगाड़ी कहाँ से मिल सकती है.\n",
            " Output : The intent is transport_query, domain is transport .\n",
            "The user utterance - Input : मुझे भारत में घूमने के लिए कुछ बेहतरीन पर्यटन स्थल बताएं.\n",
            " Output : The intent is recommendation_locations, domain is recommendation .\n",
            "The user utterance - Input : मैं स्थानीय क्षेत्र में सर्वश्रेष्ठ रेटिंग पब जानना चाहता हूं.\n",
            " Output : The intent is recommendation_locations, domain is recommendation .\n",
            "The user utterance - Input : मुझे मध्य प्रदेश में ग्वालियर के लिए रेलगाड़ी द्वारा दूरी और दिशा का पता लगाएं.\n",
            " Output : The intent is transport_query, domain is transport .\n",
            "The user utterance - Input : क्या मेरा पसंदीदा पिज़्ज़ा स्थान टेकअवे के लिए उपलब्ध है.\n",
            " Output : The intent is takeaway_query, domain is takeaway .\n",
            "The user utterance - Input : मुझे उत्तर प्रदेश के सिनेमाघरों में चल रही सबसे लोकप्रिय एक था टाइगर फिल्म के बारे में सूचित करें.\n",
            " Output : The intent is recommendation_movies, domain is recommendation .\n",
            "The user utterance - Input : मुझे अपने क्षेत्र में निकटतम आयरिश पब कहां मिल सकता है.\n",
            " Output : The intent is recommendation_locations, domain is recommendation .\n",
            "The user utterance - Input : मुझे एक स्थानीय रेस्तरां दिलवाओ.\n",
            " Output : The intent is recommendation_locations, domain is recommendation \n",
            "  \n",
            " You would be able to capture multiple domains and intents for the user utterence.\n",
            "\n",
            "  Give the output in a json format as follows, append multiple intents, domains and slots to the list below. \n",
            "  Format:\n",
            "\n",
            "  \"intent\": []\n",
            "  \"domain\": []\n",
            "\n",
            "  \n",
            "12\n",
            "আপনি কি আমাকে প্যারিস যাওয়ার জন্য একটি ফ্লাইটের পরামর্শ দিতে পারেন যেহেতু আমি খুব ঘন ঘন ভ্রমণকারী এবং বিশ্বের বিভিন্ন স্থান ঘুরে দেখতে পছন্দ করি। এছাড়াও আইফেল টাওয়ারের আশেপাশে কিছু ভাল রেস্তোরাঁ এবং হোটেলের সাথে কিছু পর্যটন স্থানের পরামর্শ দিন যা আমি ঘুরে দেখতে পারি?\n",
            "The response after prompting is:\n",
            " {'intent': ['flight_booking', 'restaurant_recommendation', 'sightseeing_recommendation', 'hotel_recommendation'], 'domain': ['travel', 'recommendation']}\n",
            "\n",
            "\n",
            "  You are an AI, that is expert in Natural Language Understanding. You should be able to predict the multiple intents and domains in english for the given Bengali input.\n",
            "  \n",
            " আপনি কি আমাকে প্যারিস যাওয়ার জন্য একটি ফ্লাইটের পরামর্শ দিতে পারেন যেহেতু আমি খুব ঘন ঘন ভ্রমণকারী এবং বিশ্বের বিভিন্ন স্থান ঘুরে দেখতে পছন্দ করি। এছাড়াও আইফেল টাওয়ারের আশেপাশে কিছু ভাল রেস্তোরাঁ এবং হোটেলের সাথে কিছু পর্যটন স্থানের পরামর্শ দিন যা আমি ঘুরে দেখতে পারি?\n",
            "  \n",
            " using the below examples in hindi, where the user utterance in given as Input and the domain and intent are given as Output.\n",
            "  The user utterance - Input : मेरे आसपास में किन स्थानों से मैं साथ ले जाने के लिए खरीदारी कर सकता हूँ.\n",
            " Output : The intent is takeaway_order, domain is takeaway .\n",
            "The user utterance - Input : मैं स्थानीय पर्यटक के रूप में कहां से खरीदारी कर सकता हूं.\n",
            " Output : The intent is recommendation_locations, domain is recommendation .\n",
            "The user utterance - Input : मैं लखनऊ के आसपास के सिनेमाघरों में कौन सी बाहुबली फिल्म देख सकता हूं.\n",
            " Output : The intent is recommendation_movies, domain is recommendation .\n",
            "The user utterance - Input : मुझे मुंबई और भोपाल के बीच कल के लिए रेलगाड़ी शेड्यूल दिखाओ.\n",
            " Output : The intent is transport_query, domain is transport .\n",
            "The user utterance - Input : मुझे दिखाओ कि मुझे रेलगाड़ी कहाँ से मिल सकती है.\n",
            " Output : The intent is transport_query, domain is transport .\n",
            "The user utterance - Input : मुझे भारत में घूमने के लिए कुछ बेहतरीन पर्यटन स्थल बताएं.\n",
            " Output : The intent is recommendation_locations, domain is recommendation .\n",
            "The user utterance - Input : मैं स्थानीय क्षेत्र में सर्वश्रेष्ठ रेटिंग पब जानना चाहता हूं.\n",
            " Output : The intent is recommendation_locations, domain is recommendation .\n",
            "The user utterance - Input : मुझे मध्य प्रदेश में ग्वालियर के लिए रेलगाड़ी द्वारा दूरी और दिशा का पता लगाएं.\n",
            " Output : The intent is transport_query, domain is transport .\n",
            "The user utterance - Input : क्या मेरा पसंदीदा पिज़्ज़ा स्थान टेकअवे के लिए उपलब्ध है.\n",
            " Output : The intent is takeaway_query, domain is takeaway .\n",
            "The user utterance - Input : मुझे उत्तर प्रदेश के सिनेमाघरों में चल रही सबसे लोकप्रिय एक था टाइगर फिल्म के बारे में सूचित करें.\n",
            " Output : The intent is recommendation_movies, domain is recommendation .\n",
            "The user utterance - Input : मुझे अपने क्षेत्र में निकटतम आयरिश पब कहां मिल सकता है.\n",
            " Output : The intent is recommendation_locations, domain is recommendation .\n",
            "The user utterance - Input : मुझे एक स्थानीय रेस्तरां दिलवाओ.\n",
            " Output : The intent is recommendation_locations, domain is recommendation .\n",
            "The user utterance - Input : मुझे पांच मील के भीतर अच्छा बर्गर कहाँ मिल सकता है.\n",
            " Output : The intent is recommendation_locations, domain is recommendation .\n",
            "The user utterance - Input : मैं इस क्षेत्र में खरीदारी के लिए कहां जा सकता हूं.\n",
            " Output : The intent is recommendation_locations, domain is recommendation .\n",
            "The user utterance - Input : olly मैं यह क्षेत्र में खरीदारी के लिए कहां जा सकता हूं.\n",
            " Output : The intent is recommendation_locations, domain is recommendation .\n",
            "The user utterance - Input : मैं एक स्थानीय पर्यटक के रूप में कहां से खरीदारी कर सकता हूं olly.\n",
            " Output : The intent is recommendation_locations, domain is recommendation \n",
            "  \n",
            " You would be able to capture multiple domains and intents for the user utterence.\n",
            "\n",
            "  Give the output in a json format as follows, append multiple intents, domains and slots to the list below. \n",
            "  Format:\n",
            "\n",
            "  \"intent\": []\n",
            "  \"domain\": []\n",
            "\n",
            "  \n",
            "16\n",
            "আপনি কি আমাকে প্যারিস যাওয়ার জন্য একটি ফ্লাইটের পরামর্শ দিতে পারেন যেহেতু আমি খুব ঘন ঘন ভ্রমণকারী এবং বিশ্বের বিভিন্ন স্থান ঘুরে দেখতে পছন্দ করি। এছাড়াও আইফেল টাওয়ারের আশেপাশে কিছু ভাল রেস্তোরাঁ এবং হোটেলের সাথে কিছু পর্যটন স্থানের পরামর্শ দিন যা আমি ঘুরে দেখতে পারি?\n",
            "The response after prompting is:\n",
            " {'intent': ['flight_booking', 'hotel_recommendation', 'restaurant_recommendation', 'sightseeing_recommendation'], 'domain': ['travel', 'recommendation']}\n",
            "\n",
            "\n",
            "  You are an AI, that is expert in Natural Language Understanding. You should be able to predict the multiple intents and domains in english for the given Bengali input.\n",
            "  \n",
            " আপনি কি আমাকে প্যারিস যাওয়ার জন্য একটি ফ্লাইটের পরামর্শ দিতে পারেন যেহেতু আমি খুব ঘন ঘন ভ্রমণকারী এবং বিশ্বের বিভিন্ন স্থান ঘুরে দেখতে পছন্দ করি। এছাড়াও আইফেল টাওয়ারের আশেপাশে কিছু ভাল রেস্তোরাঁ এবং হোটেলের সাথে কিছু পর্যটন স্থানের পরামর্শ দিন যা আমি ঘুরে দেখতে পারি?\n",
            "  \n",
            " using the below examples in hindi, where the user utterance in given as Input and the domain and intent are given as Output.\n",
            "  The user utterance - Input : मेरे आसपास में किन स्थानों से मैं साथ ले जाने के लिए खरीदारी कर सकता हूँ.\n",
            " Output : The intent is takeaway_order, domain is takeaway .\n",
            "The user utterance - Input : मैं स्थानीय पर्यटक के रूप में कहां से खरीदारी कर सकता हूं.\n",
            " Output : The intent is recommendation_locations, domain is recommendation .\n",
            "The user utterance - Input : मैं लखनऊ के आसपास के सिनेमाघरों में कौन सी बाहुबली फिल्म देख सकता हूं.\n",
            " Output : The intent is recommendation_movies, domain is recommendation .\n",
            "The user utterance - Input : मुझे मुंबई और भोपाल के बीच कल के लिए रेलगाड़ी शेड्यूल दिखाओ.\n",
            " Output : The intent is transport_query, domain is transport .\n",
            "The user utterance - Input : मुझे दिखाओ कि मुझे रेलगाड़ी कहाँ से मिल सकती है.\n",
            " Output : The intent is transport_query, domain is transport .\n",
            "The user utterance - Input : मुझे भारत में घूमने के लिए कुछ बेहतरीन पर्यटन स्थल बताएं.\n",
            " Output : The intent is recommendation_locations, domain is recommendation .\n",
            "The user utterance - Input : मैं स्थानीय क्षेत्र में सर्वश्रेष्ठ रेटिंग पब जानना चाहता हूं.\n",
            " Output : The intent is recommendation_locations, domain is recommendation .\n",
            "The user utterance - Input : मैं फॉर्च्यून गार्डन से अपना चाइनीज उठाने की उम्मीद कब कर सकता हूं.\n",
            " Output : The intent is takeaway_query, domain is takeaway .\n",
            "The user utterance - Input : मुझे मध्य प्रदेश में ग्वालियर के लिए रेलगाड़ी द्वारा दूरी और दिशा का पता लगाएं.\n",
            " Output : The intent is transport_query, domain is transport .\n",
            "The user utterance - Input : क्या मेरा पसंदीदा पिज़्ज़ा स्थान टेकअवे के लिए उपलब्ध है.\n",
            " Output : The intent is takeaway_query, domain is takeaway .\n",
            "The user utterance - Input : मुझे उत्तर प्रदेश के सिनेमाघरों में चल रही सबसे लोकप्रिय एक था टाइगर फिल्म के बारे में सूचित करें.\n",
            " Output : The intent is recommendation_movies, domain is recommendation .\n",
            "The user utterance - Input : क्या आप मुझे एक फ्लैश ब्रीफिंग दे सकते हैं.\n",
            " Output : The intent is news_query, domain is news .\n",
            "The user utterance - Input : मुझे अपने क्षेत्र में निकटतम आयरिश पब कहां मिल सकता है.\n",
            " Output : The intent is recommendation_locations, domain is recommendation .\n",
            "The user utterance - Input : क्या तुम मुझे पश्चिम बंगाल में सबसे महंगे बंगाली रेस्टोरेंट्स के बारे में बता सकते हो.\n",
            " Output : The intent is recommendation_locations, domain is recommendation .\n",
            "The user utterance - Input : मुझे एक स्थानीय रेस्तरां दिलवाओ.\n",
            " Output : The intent is recommendation_locations, domain is recommendation .\n",
            "The user utterance - Input : मुझे पांच मील के भीतर अच्छा बर्गर कहाँ मिल सकता है.\n",
            " Output : The intent is recommendation_locations, domain is recommendation .\n",
            "The user utterance - Input : मैं इस क्षेत्र में खरीदारी के लिए कहां जा सकता हूं.\n",
            " Output : The intent is recommendation_locations, domain is recommendation .\n",
            "The user utterance - Input : क्या आप मेरे आस-पास फ़र्नीचर की दुकान ढूंढ सकते हैं.\n",
            " Output : The intent is recommendation_locations, domain is recommendation .\n",
            "The user utterance - Input : olly मैं यह क्षेत्र में खरीदारी के लिए कहां जा सकता हूं.\n",
            " Output : The intent is recommendation_locations, domain is recommendation .\n",
            "The user utterance - Input : जब मैं घर आऊं तो क्या आप कृपया पिज़्ज़ा ऑर्डर कर सकते हैं.\n",
            " Output : The intent is takeaway_order, domain is takeaway .\n",
            "The user utterance - Input : मैं एक स्थानीय पर्यटक के रूप में कहां से खरीदारी कर सकता हूं olly.\n",
            " Output : The intent is recommendation_locations, domain is recommendation .\n",
            "The user utterance - Input : क्या आप मुझे बता सकते हैं कि न्यू इंडिया रेस्तरां में क्या मैं वहाँ से टेकअवे ऑर्डर कर सकता हूँ.\n",
            " Output : The intent is takeaway_query, domain is takeaway .\n",
            "The user utterance - Input : क्या आप मुझे सिएटल में उड़ान संग्रहालय जाने के लिए दिशा निर्देश दिखा सकते हैं.\n",
            " Output : The intent is transport_query, domain is transport .\n",
            "The user utterance - Input : क्या आप मुझे ग्राउंड बीफ पाने की सबसे सस्ती जगह बता सकते हैं.\n",
            " Output : The intent is recommendation_locations, domain is recommendation .\n",
            "The user utterance - Input : क्या आप कृपया स्थानीय रेस्तरां की सूची एकत्र कर सकते हैं और उन्हें मेरे पति को ईमेल कर सकते हैं.\n",
            " Output : The intent is email_sendemail, domain is email .\n",
            "The user utterance - Input : क्या आप मुझे पड़ोस में एक स्ट्रीट फेयर ढूंढ सकते हैं.\n",
            " Output : The intent is recommendation_events, domain is recommendation .\n",
            "The user utterance - Input : मुझे भारत में एक चिड़ियाघर या पशु पार्क खोजें जो इस सप्ताह के अंत में खुले.\n",
            " Output : The intent is recommendation_events, domain is recommendation .\n",
            "The user utterance - Input : olly पास का पार्क कहाँ है जहाँ मैं दौड़ने जा सकता हूँ.\n",
            " Output : The intent is recommendation_locations, domain is recommendation .\n",
            "The user utterance - Input : क्या मुझे फॉक्स डाउनटाउन से जल्द से जल्द घर के लिए उबर मिल सकता है.\n",
            " Output : The intent is transport_taxi, domain is transport .\n",
            "The user utterance - Input : क्या आप इस आयोजन के लिए मेरी बहनों के घर में स्थान निर्धारित कर सकते हैं.\n",
            " Output : The intent is calendar_set, domain is calendar .\n",
            "The user utterance - Input : मुझे फारान भोलू स्टेडियम की वास्तविकता से अवगत कराएं.\n",
            " Output : The intent is qa_definition, domain is qa .\n",
            "The user utterance - Input : मैं इंदौर के लिए रेल टिकट कहां से बुक कर सकता हूं.\n",
            " Output : The intent is transport_query, domain is transport \n",
            "  \n",
            " You would be able to capture multiple domains and intents for the user utterence.\n",
            "\n",
            "  Give the output in a json format as follows, append multiple intents, domains and slots to the list below. \n",
            "  Format:\n",
            "\n",
            "  \"intent\": []\n",
            "  \"domain\": []\n",
            "\n",
            "  \n",
            "32\n",
            "আপনি কি আমাকে প্যারিস যাওয়ার জন্য একটি ফ্লাইটের পরামর্শ দিতে পারেন যেহেতু আমি খুব ঘন ঘন ভ্রমণকারী এবং বিশ্বের বিভিন্ন স্থান ঘুরে দেখতে পছন্দ করি। এছাড়াও আইফেল টাওয়ারের আশেপাশে কিছু ভাল রেস্তোরাঁ এবং হোটেলের সাথে কিছু পর্যটন স্থানের পরামর্শ দিন যা আমি ঘুরে দেখতে পারি?\n",
            "The response after prompting is:\n",
            " {'intent': [], 'domain': []}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for users in user_query_1:\n",
        "  for k_values in k:\n",
        "    output = final(k_values , users)\n",
        "    print(k_values)\n",
        "    print(users)\n",
        "    print(output)"
      ],
      "metadata": {
        "id": "3OV7aFAmwDYB",
        "outputId": "4ba82f7f-b33e-482a-9f33-6696246a8380",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "  You are an AI, that is expert in Natural Language Understanding. You should be able to predict the multiple intents and domains in english for the given Bengali input.\n",
            "  \n",
            " স\n",
            "  \n",
            " using the below examples in hindi, where the user utterance in given as Input and the domain and intent are given as Output.\n",
            "  The user utterance - Input : एस.\n",
            " Output : The intent is play_music, domain is play .\n",
            "The user utterance - Input : सफ़ेद.\n",
            " Output : The intent is iot_hue_lightchange, domain is iot .\n",
            "The user utterance - Input : सात सौ.\n",
            " Output : The intent is datetime_convert, domain is datetime .\n",
            "The user utterance - Input : साथिया.\n",
            " Output : The intent is play_music, domain is play .\n",
            "The user utterance - Input : सुखद.\n",
            " Output : The intent is cooking_recipe, domain is cooking .\n",
            "The user utterance - Input : सागरतट.\n",
            " Output : The intent is qa_factoid, domain is qa .\n",
            "The user utterance - Input : शतरंज.\n",
            " Output : The intent is play_game, domain is play .\n",
            "The user utterance - Input : शाकाहार.\n",
            " Output : The intent is general_quirky, domain is general \n",
            "  \n",
            " You would be able to capture multiple domains and intents for the user utterence.\n",
            "\n",
            "  Give the output in a json format as follows, append multiple intents, domains and slots to the list below. \n",
            "  Format:\n",
            "\n",
            "  \"intent\": []\n",
            "  \"domain\": []\n",
            "\n",
            "  \n",
            "8\n",
            "স\n",
            "The response after prompting is:\n",
            " {'intent': ['play_music'], 'domain': ['play']}\n",
            "\n",
            "\n",
            "  You are an AI, that is expert in Natural Language Understanding. You should be able to predict the multiple intents and domains in english for the given Bengali input.\n",
            "  \n",
            " স\n",
            "  \n",
            " using the below examples in hindi, where the user utterance in given as Input and the domain and intent are given as Output.\n",
            "  The user utterance - Input : एस.\n",
            " Output : The intent is play_music, domain is play .\n",
            "The user utterance - Input : सफ़ेद.\n",
            " Output : The intent is iot_hue_lightchange, domain is iot .\n",
            "The user utterance - Input : सात सौ.\n",
            " Output : The intent is datetime_convert, domain is datetime .\n",
            "The user utterance - Input : साथिया.\n",
            " Output : The intent is play_music, domain is play .\n",
            "The user utterance - Input : सुखद.\n",
            " Output : The intent is cooking_recipe, domain is cooking .\n",
            "The user utterance - Input : सागरतट.\n",
            " Output : The intent is qa_factoid, domain is qa .\n",
            "The user utterance - Input : शतरंज.\n",
            " Output : The intent is play_game, domain is play .\n",
            "The user utterance - Input : शाकाहार.\n",
            " Output : The intent is general_quirky, domain is general .\n",
            "The user utterance - Input : सर्वश्रेष्ठ.\n",
            " Output : The intent is calendar_query, domain is calendar .\n",
            "The user utterance - Input : इसपर संगीत.\n",
            " Output : The intent is play_music, domain is play .\n",
            "The user utterance - Input : तरह मौसम.\n",
            " Output : The intent is weather_query, domain is weather .\n",
            "The user utterance - Input : संगीत.\n",
            " Output : The intent is play_music, domain is play \n",
            "  \n",
            " You would be able to capture multiple domains and intents for the user utterence.\n",
            "\n",
            "  Give the output in a json format as follows, append multiple intents, domains and slots to the list below. \n",
            "  Format:\n",
            "\n",
            "  \"intent\": []\n",
            "  \"domain\": []\n",
            "\n",
            "  \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "JSONDecodeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-5c8aa9123484>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0musers\u001b[0m \u001b[0;32min\u001b[0m \u001b[0muser_query_1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mk_values\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_values\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0musers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-45f42c8baca7>\u001b[0m in \u001b[0;36mfinal\u001b[0;34m(no_of_docs, user_query)\u001b[0m\n\u001b[1;32m     27\u001b[0m   \u001b[0;31m# Print the prompt template\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_template\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m   \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_intent_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_template\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m   \u001b[0;31m# Final response after prompting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"The response after prompting is:\\n {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-87a1b19095ef>\u001b[0m in \u001b[0;36mget_intent_label\u001b[0;34m(user_query)\u001b[0m\n\u001b[1;32m     50\u001b[0m     ]\n\u001b[1;32m     51\u001b[0m   )\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"choices\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"message\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"content\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.10/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Extra data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m: Extra data: line 2 column 1 (char 55)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kIeQ95TPCJIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get similarity score with actual\n",
        "calculate_cosine_similarity(output, expected)"
      ],
      "metadata": {
        "id": "V23oiEtr84kH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save output to csv"
      ],
      "metadata": {
        "id": "DJ6upd2k8Ik5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "returned_string = output\n",
        "csv_file = 'output.csv'\n",
        "\n",
        "# Open the CSV file in write mode and create a CSV writer\n",
        "with open(csv_file, mode='w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "\n",
        "    # Write each character as a separate row\n",
        "    for i in output_list:\n",
        "        writer.writerow([i])\n",
        "\n",
        "print(f'Saved the string in \"{csv_file}\" as separate rows in a CSV file.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Md4e4cnn5vlL",
        "outputId": "40f3769b-05be-4e9c-a897-5be58cdd66d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved the string in \"output.csv\" as separate rows in a CSV file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "poafs9BI8Dx5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}